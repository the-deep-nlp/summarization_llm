{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv() # Loads the environment variables\n",
    "OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"outputs/summaries1.csv\", usecols=[\"input_excerpts\", \"summaries_llm\", \"summaries_inhouse\", \"tag_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SummEvaluation:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def get_geval_score(\n",
    "        self,\n",
    "        criteria: str,\n",
    "        steps: str,\n",
    "        document: str,\n",
    "        summary: str,\n",
    "        metric_name: str\n",
    "    ):\n",
    "        prompt = self.prompt.format(\n",
    "            criteria=criteria,\n",
    "            steps=steps,\n",
    "            metric_name=metric_name,\n",
    "            document=document,\n",
    "            summary=summary,\n",
    "        )\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-4\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=0,\n",
    "            max_tokens=5,\n",
    "            top_p=1,\n",
    "            frequency_penalty=0,\n",
    "            presence_penalty=0,\n",
    "        )\n",
    "        return response.choices[0].message.content.strip()\n",
    "\n",
    "    def eval_summ_using_prompt(self, df):\n",
    "        self.prompt = \"\"\"\n",
    "            You will be given one summary written for an article. Your task is to rate the summary on one metric.\n",
    "            Please make sure you read and understand these instructions very carefully. \n",
    "            Please keep this document open while reviewing, and refer to it as needed.\n",
    "\n",
    "            Evaluation Criteria:\n",
    "\n",
    "            {criteria}\n",
    "\n",
    "            Evaluation Steps:\n",
    "\n",
    "            {steps}\n",
    "\n",
    "            Example:\n",
    "\n",
    "            Source Text:\n",
    "\n",
    "            {document}\n",
    "\n",
    "            Summary:\n",
    "\n",
    "            {summary}\n",
    "\n",
    "            Evaluation Form (scores ONLY):\n",
    "\n",
    "            - {metric_name}\n",
    "        \"\"\"\n",
    "\n",
    "        # Metric 1: Relevance\n",
    "\n",
    "        RELEVANCY_SCORE_CRITERIA = \"\"\"\n",
    "        Relevance(1-5) - selection of important content from the source. \\\n",
    "        The summary should include only important information from the source document. \\\n",
    "        Annotators were instructed to penalize summaries which contained redundancies and excess information.\n",
    "        \"\"\"\n",
    "\n",
    "        RELEVANCY_SCORE_STEPS = \"\"\"\n",
    "        1. Read the summary and the source document carefully.\n",
    "        2. Compare the summary to the source document and identify the main points of the article.\n",
    "        3. Assess how well the summary covers the main points of the article, and how much irrelevant or redundant information it contains.\n",
    "        4. Assign a relevance score from 1 to 5.\n",
    "        \"\"\"\n",
    "\n",
    "        # Metric 2: Coherence\n",
    "\n",
    "        COHERENCE_SCORE_CRITERIA = \"\"\"\n",
    "        Coherence(1-5) - the collective quality of all sentences. \\\n",
    "        We align this dimension with the DUC quality question of structure and coherence \\\n",
    "        whereby \"the summary should be well-structured and well-organized. \\\n",
    "        The summary should not just be a heap of related information, but should build from sentence to a\\\n",
    "        coherent body of information about a topic.\"\n",
    "        \"\"\"\n",
    "\n",
    "        COHERENCE_SCORE_STEPS = \"\"\"\n",
    "        1. Read the article carefully and identify the main topic and key points.\n",
    "        2. Read the summary and compare it to the article. Check if the summary covers the main topic and key points of the article,\n",
    "        and if it presents them in a clear and logical order.\n",
    "        3. Assign a score for coherence on a scale of 1 to 5, where 1 is the lowest and 5 is the highest based on the Evaluation Criteria.\n",
    "        \"\"\"\n",
    "\n",
    "        # Metric 3: Consistency\n",
    "\n",
    "        CONSISTENCY_SCORE_CRITERIA = \"\"\"\n",
    "        Consistency(1-5) - the factual alignment between the summary and the summarized source. \\\n",
    "        A factually consistent summary contains only statements that are entailed by the source document. \\\n",
    "        Annotators were also asked to penalize summaries that contained hallucinated facts.\n",
    "        \"\"\"\n",
    "\n",
    "        CONSISTENCY_SCORE_STEPS = \"\"\"\n",
    "        1. Read the article carefully and identify the main facts and details it presents.\n",
    "        2. Read the summary and compare it to the article. Check if the summary contains any factual errors that are not supported by the article.\n",
    "        3. Assign a score for consistency based on the Evaluation Criteria.\n",
    "        \"\"\"\n",
    "\n",
    "        # Metric 4: Fluency\n",
    "\n",
    "        FLUENCY_SCORE_CRITERIA = \"\"\"\n",
    "        Fluency(1-3): the quality of the summary in terms of grammar, spelling, punctuation, word choice, and sentence structure.\n",
    "        1: Poor. The summary has many errors that make it hard to understand or sound unnatural.\n",
    "        2: Fair. The summary has some errors that affect the clarity or smoothness of the text, but the main points are still comprehensible.\n",
    "        3: Good. The summary has few or no errors and is easy to read and follow.\n",
    "        \"\"\"\n",
    "\n",
    "        FLUENCY_SCORE_STEPS = \"\"\"\n",
    "        Read the summary and evaluate its fluency based on the given criteria. Assign a fluency score from 1 to 3.\n",
    "        \"\"\"\n",
    "\n",
    "        self.evaluation_metrics = {\n",
    "            \"relevance\": (RELEVANCY_SCORE_CRITERIA, RELEVANCY_SCORE_STEPS),\n",
    "            \"coherence\": (COHERENCE_SCORE_CRITERIA, COHERENCE_SCORE_STEPS),\n",
    "            \"consistency\": (CONSISTENCY_SCORE_CRITERIA, CONSISTENCY_SCORE_STEPS),\n",
    "            \"fluency\": (FLUENCY_SCORE_CRITERIA, FLUENCY_SCORE_STEPS)\n",
    "        }\n",
    "        results = {}\n",
    "        for eval_type in self.evaluation_metrics.keys():\n",
    "            results.update({\n",
    "                f\"{eval_type}_llm\": [],\n",
    "                f\"{eval_type}_inhouse\": []\n",
    "            })\n",
    "        for eval_type, (criteria, steps) in self.evaluation_metrics.items():\n",
    "            results[f\"{eval_type}_llm\"] = df.apply(lambda x: self.get_geval_score(criteria, steps, x[\"input_excerpts\"], x[\"summaries_llm\"], eval_type), axis=1).tolist()\n",
    "            results[f\"{eval_type}_inhouse\"] = df.apply(lambda x: self.get_geval_score(criteria, steps, x[\"input_excerpts\"], x[\"summaries_inhouse\"], eval_type), axis=1).tolist()\n",
    "        \n",
    "        return results\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_excerpts</th>\n",
       "      <th>summaries_llm</th>\n",
       "      <th>summaries_inhouse</th>\n",
       "      <th>tag_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Current needs include WASH, shelter, health, a...</td>\n",
       "      <td>The earthquake in Morocco has caused significa...</td>\n",
       "      <td>Moroccan authorities are continuing their effo...</td>\n",
       "      <td>protection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Current needs include WASH, shelter, health, a...</td>\n",
       "      <td>The earthquake in Morocco has caused extensive...</td>\n",
       "      <td>The devastating earthquake in Morocco has left...</td>\n",
       "      <td>shelter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>According to an Unosat analysis performed on 1...</td>\n",
       "      <td>According to an Unosat analysis on 10/9/2023, ...</td>\n",
       "      <td>The earthquake that struck Morocco last week h...</td>\n",
       "      <td>education</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Current needs include WASH, shelter, health, a...</td>\n",
       "      <td>Caritas Morocco continues to provide aid to th...</td>\n",
       "      <td>The earthquake in Morocco, which killed at lea...</td>\n",
       "      <td>food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The average standard of living of households i...</td>\n",
       "      <td>The average standard of living of households i...</td>\n",
       "      <td>The Moroccan government has announced that it ...</td>\n",
       "      <td>livelihoods</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>They are among 60 firefighters from 14 UK fire...</td>\n",
       "      <td>The earthquake in Morocco has caused significa...</td>\n",
       "      <td>The devastating earthquake that struck Morocco...</td>\n",
       "      <td>health</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>They are among 60 firefighters from 14 UK fire...</td>\n",
       "      <td>The 6.8 magnitude earthquake in Morocco's High...</td>\n",
       "      <td>Emergency supplies are being sought to help th...</td>\n",
       "      <td>cross</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>All international airports and ports are funct...</td>\n",
       "      <td>All international airports and ports are funct...</td>\n",
       "      <td>The Moroccan government has confirmed that it ...</td>\n",
       "      <td>logistics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Through these completed activities, AFH has ma...</td>\n",
       "      <td>Through completed activities, AFH has made a m...</td>\n",
       "      <td>The British Farmers' Fund (AFH) has completed ...</td>\n",
       "      <td>nutrition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>In recent years, the Moroccan government and d...</td>\n",
       "      <td>Summary 1: This article discusses aid programs...</td>\n",
       "      <td>Moroccan aid agency CARE Maroc has launched a ...</td>\n",
       "      <td>agriculture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Current needs include WASH, shelter, health, a...</td>\n",
       "      <td>The earthquake in Morocco has caused significa...</td>\n",
       "      <td>The Moroccan army is providing emergency shelt...</td>\n",
       "      <td>wash</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       input_excerpts  \\\n",
       "0   Current needs include WASH, shelter, health, a...   \n",
       "1   Current needs include WASH, shelter, health, a...   \n",
       "2   According to an Unosat analysis performed on 1...   \n",
       "3   Current needs include WASH, shelter, health, a...   \n",
       "4   The average standard of living of households i...   \n",
       "5   They are among 60 firefighters from 14 UK fire...   \n",
       "6   They are among 60 firefighters from 14 UK fire...   \n",
       "7   All international airports and ports are funct...   \n",
       "8   Through these completed activities, AFH has ma...   \n",
       "9   In recent years, the Moroccan government and d...   \n",
       "10  Current needs include WASH, shelter, health, a...   \n",
       "\n",
       "                                        summaries_llm  \\\n",
       "0   The earthquake in Morocco has caused significa...   \n",
       "1   The earthquake in Morocco has caused extensive...   \n",
       "2   According to an Unosat analysis on 10/9/2023, ...   \n",
       "3   Caritas Morocco continues to provide aid to th...   \n",
       "4   The average standard of living of households i...   \n",
       "5   The earthquake in Morocco has caused significa...   \n",
       "6   The 6.8 magnitude earthquake in Morocco's High...   \n",
       "7   All international airports and ports are funct...   \n",
       "8   Through completed activities, AFH has made a m...   \n",
       "9   Summary 1: This article discusses aid programs...   \n",
       "10  The earthquake in Morocco has caused significa...   \n",
       "\n",
       "                                    summaries_inhouse     tag_name  \n",
       "0   Moroccan authorities are continuing their effo...   protection  \n",
       "1   The devastating earthquake in Morocco has left...      shelter  \n",
       "2   The earthquake that struck Morocco last week h...    education  \n",
       "3   The earthquake in Morocco, which killed at lea...         food  \n",
       "4   The Moroccan government has announced that it ...  livelihoods  \n",
       "5   The devastating earthquake that struck Morocco...       health  \n",
       "6   Emergency supplies are being sought to help th...        cross  \n",
       "7   The Moroccan government has confirmed that it ...    logistics  \n",
       "8   The British Farmers' Fund (AFH) has completed ...    nutrition  \n",
       "9   Moroccan aid agency CARE Maroc has launched a ...  agriculture  \n",
       "10  The Moroccan army is providing emergency shelt...         wash  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AuthenticationError",
     "evalue": "No API key provided. You can set your API key in code using 'openai.api_key = <API-KEY>', or you can set the environment variable OPENAI_API_KEY=<API-KEY>). If your API key is stored in a file, you can point the openai module at it with 'openai.api_key_path = <PATH>'. You can generate API keys in the OpenAI web interface. See https://platform.openai.com/account/api-keys for details.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAuthenticationError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m summ_prompt \u001b[39m=\u001b[39m SummEvaluation()\n\u001b[0;32m----> 2\u001b[0m results \u001b[39m=\u001b[39m summ_prompt\u001b[39m.\u001b[39;49meval_summ_using_prompt(df)\n",
      "Cell \u001b[0;32mIn[4], line 132\u001b[0m, in \u001b[0;36mSummEvaluation.eval_summ_using_prompt\u001b[0;34m(self, df)\u001b[0m\n\u001b[1;32m    127\u001b[0m     results\u001b[39m.\u001b[39mupdate({\n\u001b[1;32m    128\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00meval_type\u001b[39m}\u001b[39;00m\u001b[39m_llm\u001b[39m\u001b[39m\"\u001b[39m: [],\n\u001b[1;32m    129\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00meval_type\u001b[39m}\u001b[39;00m\u001b[39m_inhouse\u001b[39m\u001b[39m\"\u001b[39m: []\n\u001b[1;32m    130\u001b[0m     })\n\u001b[1;32m    131\u001b[0m \u001b[39mfor\u001b[39;00m eval_type, (criteria, steps) \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mevaluation_metrics\u001b[39m.\u001b[39mitems():\n\u001b[0;32m--> 132\u001b[0m     results[\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00meval_type\u001b[39m}\u001b[39;00m\u001b[39m_llm\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39;49mapply(\u001b[39mlambda\u001b[39;49;00m x: \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_geval_score(criteria, steps, x[\u001b[39m\"\u001b[39;49m\u001b[39minput_excerpts\u001b[39;49m\u001b[39m\"\u001b[39;49m], x[\u001b[39m\"\u001b[39;49m\u001b[39msummaries_llm\u001b[39;49m\u001b[39m\"\u001b[39;49m], eval_type), axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\u001b[39m.\u001b[39mtolist()\n\u001b[1;32m    133\u001b[0m     results[\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00meval_type\u001b[39m}\u001b[39;00m\u001b[39m_inhouse\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_geval_score(criteria, steps, x[\u001b[39m\"\u001b[39m\u001b[39minput_excerpts\u001b[39m\u001b[39m\"\u001b[39m], x[\u001b[39m\"\u001b[39m\u001b[39msummaries_inhouse\u001b[39m\u001b[39m\"\u001b[39m], eval_type), axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mtolist()\n\u001b[1;32m    135\u001b[0m \u001b[39mreturn\u001b[39;00m results\n",
      "File \u001b[0;32m~/projects/deepl/summarization_llm/.venv/lib/python3.8/site-packages/pandas/core/frame.py:9423\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[0;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[1;32m   9412\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapply\u001b[39;00m \u001b[39mimport\u001b[39;00m frame_apply\n\u001b[1;32m   9414\u001b[0m op \u001b[39m=\u001b[39m frame_apply(\n\u001b[1;32m   9415\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   9416\u001b[0m     func\u001b[39m=\u001b[39mfunc,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   9421\u001b[0m     kwargs\u001b[39m=\u001b[39mkwargs,\n\u001b[1;32m   9422\u001b[0m )\n\u001b[0;32m-> 9423\u001b[0m \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39;49mapply()\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mapply\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/projects/deepl/summarization_llm/.venv/lib/python3.8/site-packages/pandas/core/apply.py:678\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw:\n\u001b[1;32m    676\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_raw()\n\u001b[0;32m--> 678\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[0;32m~/projects/deepl/summarization_llm/.venv/lib/python3.8/site-packages/pandas/core/apply.py:798\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    797\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_standard\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 798\u001b[0m     results, res_index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_series_generator()\n\u001b[1;32m    800\u001b[0m     \u001b[39m# wrap results\u001b[39;00m\n\u001b[1;32m    801\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwrap_results(results, res_index)\n",
      "File \u001b[0;32m~/projects/deepl/summarization_llm/.venv/lib/python3.8/site-packages/pandas/core/apply.py:814\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    811\u001b[0m \u001b[39mwith\u001b[39;00m option_context(\u001b[39m\"\u001b[39m\u001b[39mmode.chained_assignment\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    812\u001b[0m     \u001b[39mfor\u001b[39;00m i, v \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(series_gen):\n\u001b[1;32m    813\u001b[0m         \u001b[39m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[0;32m--> 814\u001b[0m         results[i] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mf(v)\n\u001b[1;32m    815\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[1;32m    816\u001b[0m             \u001b[39m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[1;32m    817\u001b[0m             \u001b[39m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[1;32m    818\u001b[0m             results[i] \u001b[39m=\u001b[39m results[i]\u001b[39m.\u001b[39mcopy(deep\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[4], line 132\u001b[0m, in \u001b[0;36mSummEvaluation.eval_summ_using_prompt.<locals>.<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    127\u001b[0m     results\u001b[39m.\u001b[39mupdate({\n\u001b[1;32m    128\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00meval_type\u001b[39m}\u001b[39;00m\u001b[39m_llm\u001b[39m\u001b[39m\"\u001b[39m: [],\n\u001b[1;32m    129\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00meval_type\u001b[39m}\u001b[39;00m\u001b[39m_inhouse\u001b[39m\u001b[39m\"\u001b[39m: []\n\u001b[1;32m    130\u001b[0m     })\n\u001b[1;32m    131\u001b[0m \u001b[39mfor\u001b[39;00m eval_type, (criteria, steps) \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mevaluation_metrics\u001b[39m.\u001b[39mitems():\n\u001b[0;32m--> 132\u001b[0m     results[\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00meval_type\u001b[39m}\u001b[39;00m\u001b[39m_llm\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_geval_score(criteria, steps, x[\u001b[39m\"\u001b[39;49m\u001b[39minput_excerpts\u001b[39;49m\u001b[39m\"\u001b[39;49m], x[\u001b[39m\"\u001b[39;49m\u001b[39msummaries_llm\u001b[39;49m\u001b[39m\"\u001b[39;49m], eval_type), axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mtolist()\n\u001b[1;32m    133\u001b[0m     results[\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00meval_type\u001b[39m}\u001b[39;00m\u001b[39m_inhouse\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_geval_score(criteria, steps, x[\u001b[39m\"\u001b[39m\u001b[39minput_excerpts\u001b[39m\u001b[39m\"\u001b[39m], x[\u001b[39m\"\u001b[39m\u001b[39msummaries_inhouse\u001b[39m\u001b[39m\"\u001b[39m], eval_type), axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mtolist()\n\u001b[1;32m    135\u001b[0m \u001b[39mreturn\u001b[39;00m results\n",
      "Cell \u001b[0;32mIn[4], line 20\u001b[0m, in \u001b[0;36mSummEvaluation.get_geval_score\u001b[0;34m(self, criteria, steps, document, summary, metric_name)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_geval_score\u001b[39m(\n\u001b[1;32m      6\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m      7\u001b[0m     criteria: \u001b[39mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     11\u001b[0m     metric_name: \u001b[39mstr\u001b[39m\n\u001b[1;32m     12\u001b[0m ):\n\u001b[1;32m     13\u001b[0m     prompt \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprompt\u001b[39m.\u001b[39mformat(\n\u001b[1;32m     14\u001b[0m         criteria\u001b[39m=\u001b[39mcriteria,\n\u001b[1;32m     15\u001b[0m         steps\u001b[39m=\u001b[39msteps,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     18\u001b[0m         summary\u001b[39m=\u001b[39msummary,\n\u001b[1;32m     19\u001b[0m     )\n\u001b[0;32m---> 20\u001b[0m     response \u001b[39m=\u001b[39m openai\u001b[39m.\u001b[39;49mChatCompletion\u001b[39m.\u001b[39;49mcreate(\n\u001b[1;32m     21\u001b[0m         model\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mgpt-4\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     22\u001b[0m         messages\u001b[39m=\u001b[39;49m[{\u001b[39m\"\u001b[39;49m\u001b[39mrole\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39muser\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mcontent\u001b[39;49m\u001b[39m\"\u001b[39;49m: prompt}],\n\u001b[1;32m     23\u001b[0m         temperature\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m,\n\u001b[1;32m     24\u001b[0m         max_tokens\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m,\n\u001b[1;32m     25\u001b[0m         top_p\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m     26\u001b[0m         frequency_penalty\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m,\n\u001b[1;32m     27\u001b[0m         presence_penalty\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m,\n\u001b[1;32m     28\u001b[0m     )\n\u001b[1;32m     29\u001b[0m     \u001b[39mreturn\u001b[39;00m response\u001b[39m.\u001b[39mchoices[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mmessage\u001b[39m.\u001b[39mcontent\u001b[39m.\u001b[39mstrip()\n",
      "File \u001b[0;32m~/projects/deepl/summarization_llm/.venv/lib/python3.8/site-packages/openai/api_resources/chat_completion.py:25\u001b[0m, in \u001b[0;36mChatCompletion.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     26\u001b[0m     \u001b[39mexcept\u001b[39;00m TryAgain \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     27\u001b[0m         \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m time\u001b[39m.\u001b[39mtime() \u001b[39m>\u001b[39m start \u001b[39m+\u001b[39m timeout:\n",
      "File \u001b[0;32m~/projects/deepl/summarization_llm/.venv/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py:151\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    130\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[1;32m    131\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\n\u001b[1;32m    139\u001b[0m ):\n\u001b[1;32m    140\u001b[0m     (\n\u001b[1;32m    141\u001b[0m         deployment_id,\n\u001b[1;32m    142\u001b[0m         engine,\n\u001b[1;32m    143\u001b[0m         timeout,\n\u001b[1;32m    144\u001b[0m         stream,\n\u001b[1;32m    145\u001b[0m         headers,\n\u001b[1;32m    146\u001b[0m         request_timeout,\n\u001b[1;32m    147\u001b[0m         typed_api_type,\n\u001b[1;32m    148\u001b[0m         requestor,\n\u001b[1;32m    149\u001b[0m         url,\n\u001b[1;32m    150\u001b[0m         params,\n\u001b[0;32m--> 151\u001b[0m     ) \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49m__prepare_create_request(\n\u001b[1;32m    152\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mparams\n\u001b[1;32m    153\u001b[0m     )\n\u001b[1;32m    155\u001b[0m     response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39mrequest(\n\u001b[1;32m    156\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mpost\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    157\u001b[0m         url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    162\u001b[0m         request_timeout\u001b[39m=\u001b[39mrequest_timeout,\n\u001b[1;32m    163\u001b[0m     )\n\u001b[1;32m    165\u001b[0m     \u001b[39mif\u001b[39;00m stream:\n\u001b[1;32m    166\u001b[0m         \u001b[39m# must be an iterator\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/deepl/summarization_llm/.venv/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py:108\u001b[0m, in \u001b[0;36mEngineAPIResource.__prepare_create_request\u001b[0;34m(cls, api_key, api_base, api_type, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[39melif\u001b[39;00m timeout \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    106\u001b[0m     params[\u001b[39m\"\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m MAX_TIMEOUT\n\u001b[0;32m--> 108\u001b[0m requestor \u001b[39m=\u001b[39m api_requestor\u001b[39m.\u001b[39;49mAPIRequestor(\n\u001b[1;32m    109\u001b[0m     api_key,\n\u001b[1;32m    110\u001b[0m     api_base\u001b[39m=\u001b[39;49mapi_base,\n\u001b[1;32m    111\u001b[0m     api_type\u001b[39m=\u001b[39;49mapi_type,\n\u001b[1;32m    112\u001b[0m     api_version\u001b[39m=\u001b[39;49mapi_version,\n\u001b[1;32m    113\u001b[0m     organization\u001b[39m=\u001b[39;49morganization,\n\u001b[1;32m    114\u001b[0m )\n\u001b[1;32m    115\u001b[0m url \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mclass_url(engine, api_type, api_version)\n\u001b[1;32m    116\u001b[0m \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    117\u001b[0m     deployment_id,\n\u001b[1;32m    118\u001b[0m     engine,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    126\u001b[0m     params,\n\u001b[1;32m    127\u001b[0m )\n",
      "File \u001b[0;32m~/projects/deepl/summarization_llm/.venv/lib/python3.8/site-packages/openai/api_requestor.py:139\u001b[0m, in \u001b[0;36mAPIRequestor.__init__\u001b[0;34m(self, key, api_base, api_type, api_version, organization)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\n\u001b[1;32m    131\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    132\u001b[0m     key\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    136\u001b[0m     organization\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    137\u001b[0m ):\n\u001b[1;32m    138\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_base \u001b[39m=\u001b[39m api_base \u001b[39mor\u001b[39;00m openai\u001b[39m.\u001b[39mapi_base\n\u001b[0;32m--> 139\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key \u001b[39m=\u001b[39m key \u001b[39mor\u001b[39;00m util\u001b[39m.\u001b[39;49mdefault_api_key()\n\u001b[1;32m    140\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_type \u001b[39m=\u001b[39m (\n\u001b[1;32m    141\u001b[0m         ApiType\u001b[39m.\u001b[39mfrom_str(api_type)\n\u001b[1;32m    142\u001b[0m         \u001b[39mif\u001b[39;00m api_type\n\u001b[1;32m    143\u001b[0m         \u001b[39melse\u001b[39;00m ApiType\u001b[39m.\u001b[39mfrom_str(openai\u001b[39m.\u001b[39mapi_type)\n\u001b[1;32m    144\u001b[0m     )\n\u001b[1;32m    145\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_version \u001b[39m=\u001b[39m api_version \u001b[39mor\u001b[39;00m openai\u001b[39m.\u001b[39mapi_version\n",
      "File \u001b[0;32m~/projects/deepl/summarization_llm/.venv/lib/python3.8/site-packages/openai/util.py:186\u001b[0m, in \u001b[0;36mdefault_api_key\u001b[0;34m()\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[39mreturn\u001b[39;00m openai\u001b[39m.\u001b[39mapi_key\n\u001b[1;32m    185\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 186\u001b[0m     \u001b[39mraise\u001b[39;00m openai\u001b[39m.\u001b[39merror\u001b[39m.\u001b[39mAuthenticationError(\n\u001b[1;32m    187\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo API key provided. You can set your API key in code using \u001b[39m\u001b[39m'\u001b[39m\u001b[39mopenai.api_key = <API-KEY>\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, or you can set the environment variable OPENAI_API_KEY=<API-KEY>). If your API key is stored in a file, you can point the openai module at it with \u001b[39m\u001b[39m'\u001b[39m\u001b[39mopenai.api_key_path = <PATH>\u001b[39m\u001b[39m'\u001b[39m\u001b[39m. You can generate API keys in the OpenAI web interface. See https://platform.openai.com/account/api-keys for details.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    188\u001b[0m     )\n",
      "\u001b[0;31mAuthenticationError\u001b[0m: No API key provided. You can set your API key in code using 'openai.api_key = <API-KEY>', or you can set the environment variable OPENAI_API_KEY=<API-KEY>). If your API key is stored in a file, you can point the openai module at it with 'openai.api_key_path = <PATH>'. You can generate API keys in the OpenAI web interface. See https://platform.openai.com/account/api-keys for details."
     ]
    }
   ],
   "source": [
    "summ_prompt = SummEvaluation()\n",
    "results = summ_prompt.eval_summ_using_prompt(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scores = pd.DataFrame.from_dict(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = pd.concat([df, df_scores], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
